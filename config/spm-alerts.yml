# Alertas SPM (Service Performance Monitoring) para Fintelli
# Arquivo: config/spm-alerts.yml

groups:
  - name: fintelli-spm-alerts
    rules:
      # ========================================
      # ALERTAS DE LAT√äNCIA
      # ========================================

      - alert: HighTransactionLatencyP95
        expr: |
          histogram_quantile(0.95, 
            rate(duration_bucket{operation=~"/api/transactions.*"}[5m])
          ) > 0.5
        for: 2m
        labels:
          severity: warning
          service: fintelli-backend
          category: latency
          sla_impact: high
        annotations:
          summary: "Lat√™ncia alta em transa√ß√µes (P95)"
          description: |
            A lat√™ncia P95 das transa√ß√µes est√° em {{ $value | humanizeDuration }}, 
            acima do threshold de 500ms. Isso pode impactar a experi√™ncia do usu√°rio.

            A√ß√µes recomendadas:
            - Verificar performance do PostgreSQL
            - Analisar queries lentas
            - Verificar utiliza√ß√£o de CPU/mem√≥ria
          runbook_url: "https://wiki.fintelli.com/runbooks/high-latency"
          dashboard_url: "http://localhost:3000/d/fintelli-spm"

      - alert: CriticalTransactionLatencyP95
        expr: |
          histogram_quantile(0.95, 
            rate(duration_bucket{operation=~"/api/transactions.*"}[5m])
          ) > 1.0
        for: 1m
        labels:
          severity: critical
          service: fintelli-backend
          category: latency
          sla_impact: critical
        annotations:
          summary: "Lat√™ncia CR√çTICA em transa√ß√µes (P95 > 1s)"
          description: |
            üö® ALERTA CR√çTICO: Lat√™ncia P95 das transa√ß√µes √© {{ $value | humanizeDuration }}.
            Sistema pode estar indispon√≠vel para usu√°rios.

            A√ß√µes URGENTES:
            - Verificar se sistema precisa de restart
            - Escalar recursos imediatamente
            - Ativar procedimento de emerg√™ncia
          runbook_url: "https://wiki.fintelli.com/runbooks/critical-latency"

      # ========================================
      # ALERTAS DE TAXA DE ERRO
      # ========================================

      - alert: HighErrorRate
        expr: |
          (
            rate(calls_total{service_name="fintelli-backend",status_code=~"5.."}[5m]) /
            rate(calls_total{service_name="fintelli-backend"}[5m])
          ) * 100 > 1
        for: 1m
        labels:
          severity: warning
          service: fintelli-backend
          category: errors
          sla_impact: high
        annotations:
          summary: "Taxa de erro elevada ({{ $value | humanizePercentage }})"
          description: |
            A taxa de erro do backend est√° em {{ $value | humanizePercentage }}, 
            acima do threshold de 1%.

            A√ß√µes recomendadas:
            - Verificar logs de erro recentes
            - Investigar mudan√ßas de c√≥digo recentes
            - Verificar integra√ß√µes externas

      - alert: CriticalErrorRate
        expr: |
          (
            rate(calls_total{service_name="fintelli-backend",status_code=~"5.."}[5m]) /
            rate(calls_total{service_name="fintelli-backend"}[5m])
          ) * 100 > 5
        for: 30s
        labels:
          severity: critical
          service: fintelli-backend
          category: errors
          sla_impact: critical
        annotations:
          summary: "Taxa de erro CR√çTICA ({{ $value | humanizePercentage }})"
          description: |
            üö® ALERTA CR√çTICO: Taxa de erro em {{ $value | humanizePercentage }}.
            M√∫ltiplas falhas detectadas.

            A√ß√µes URGENTES:
            - Considerar rollback do √∫ltimo deploy
            - Ativar procedimento de incident response
            - Comunicar stakeholders

      # ========================================
      # ALERTAS DE DISPONIBILIDADE
      # ========================================

      - alert: LowServiceAvailability
        expr: |
          (
            1 - (
              rate(calls_total{service_name="fintelli-backend",status_code=~"5.."}[5m]) /
              rate(calls_total{service_name="fintelli-backend"}[5m])
            )
          ) * 100 < 99.9
        for: 5m
        labels:
          severity: critical
          service: fintelli-backend
          category: availability
          sla_impact: critical
        annotations:
          summary: "Disponibilidade abaixo do SLA ({{ $value | humanizePercentage }})"
          description: |
            üö® SLA VIOLADO: Disponibilidade do servi√ßo est√° em {{ $value | humanizePercentage }}, 
            abaixo do SLA de 99.9%.

            A√ß√µes URGENTES:
            - Ativar equipe de plant√£o
            - Investigar causa raiz
            - Preparar relat√≥rio de incident

      # ========================================
      # ALERTAS DE THROUGHPUT
      # ========================================

      - alert: LowThroughput
        expr: |
          rate(calls_total{service_name="fintelli-backend"}[5m]) < 10
        for: 5m
        labels:
          severity: warning
          service: fintelli-backend
          category: throughput
          sla_impact: medium
        annotations:
          summary: "Throughput baixo ({{ $value | humanize }} req/s)"
          description: |
            O throughput do sistema est√° em {{ $value | humanize }} req/s, 
            abaixo do esperado (>10 req/s).

            Poss√≠veis causas:
            - Redu√ß√£o no tr√°fego de usu√°rios
            - Problemas de conectividade
            - Gargalos de performance

      - alert: ZeroThroughput
        expr: |
          rate(calls_total{service_name="fintelli-backend"}[5m]) == 0
        for: 2m
        labels:
          severity: critical
          service: fintelli-backend
          category: throughput
          sla_impact: critical
        annotations:
          summary: "Sistema sem tr√°fego - Poss√≠vel indisponibilidade"
          description: |
            üö® ALERTA CR√çTICO: Nenhuma requisi√ß√£o detectada nos √∫ltimos 2 minutos.
            Sistema pode estar completamente indispon√≠vel.

            A√ß√µes URGENTES:
            - Verificar se servi√ßos est√£o rodando
            - Testar conectividade
            - Verificar load balancer/proxy

      # ========================================
      # ALERTAS DE DEPEND√äNCIAS
      # ========================================

      - alert: DatabaseHighLatency
        expr: |
          histogram_quantile(0.95,
            rate(duration_bucket{operation=~".*sql.*|.*postgres.*"}[5m])
          ) > 0.1
        for: 3m
        labels:
          severity: warning
          service: postgres
          category: database
          sla_impact: high
        annotations:
          summary: "Lat√™ncia alta no PostgreSQL ({{ $value | humanizeDuration }})"
          description: |
            A lat√™ncia P95 do PostgreSQL est√° em {{ $value | humanizeDuration }}.

            A√ß√µes recomendadas:
            - Verificar queries lentas
            - Analisar utiliza√ß√£o de recursos do DB
            - Considerar otimiza√ß√£o de √≠ndices

      - alert: CacheHighLatency
        expr: |
          histogram_quantile(0.95,
            rate(duration_bucket{operation=~".*redis.*|.*cache.*"}[5m])
          ) > 0.01
        for: 3m
        labels:
          severity: warning
          service: redis
          category: cache
          sla_impact: medium
        annotations:
          summary: "Lat√™ncia alta no Redis ({{ $value | humanizeDuration }})"
          description: |
            A lat√™ncia P95 do Redis est√° em {{ $value | humanizeDuration }}.
            Redis geralmente deve responder em < 10ms.

            A√ß√µes recomendadas:
            - Verificar utiliza√ß√£o de mem√≥ria do Redis
            - Analisar comandos lentos
            - Verificar configura√ß√£o de persist√™ncia

      # ========================================
      # ALERTAS DE TEND√äNCIA
      # ========================================

      - alert: LatencyTrendIncreasing
        expr: |
          (
            histogram_quantile(0.95, rate(duration_bucket{service_name="fintelli-backend"}[5m])) -
            histogram_quantile(0.95, rate(duration_bucket{service_name="fintelli-backend"}[5m] offset 15m))
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          service: fintelli-backend
          category: trend
          sla_impact: medium
        annotations:
          summary: "Tend√™ncia de aumento na lat√™ncia detectada"
          description: |
            A lat√™ncia P95 aumentou {{ $value | humanizeDuration }} nos √∫ltimos 15 minutos.
            Tend√™ncia crescente pode indicar degrada√ß√£o gradual.

            A√ß√µes preventivas:
            - Monitorar de perto
            - Investigar causas potenciais
            - Preparar plano de conting√™ncia

      - alert: ThroughputTrendDecreasing
        expr: |
          (
            rate(calls_total{service_name="fintelli-backend"}[5m]) -
            rate(calls_total{service_name="fintelli-backend"}[5m] offset 15m)
          ) < -10
        for: 5m
        labels:
          severity: warning
          service: fintelli-backend
          category: trend
          sla_impact: medium
        annotations:
          summary: "Tend√™ncia de queda no throughput detectada"
          description: |
            O throughput diminuiu {{ $value | humanize }} req/s nos √∫ltimos 15 minutos.

            Poss√≠veis causas:
            - Problemas de performance emergentes
            - Redu√ß√£o natural no tr√°fego
            - Problemas de conectividade

      # ========================================
      # ALERTAS DE ANOMALIA
      # ========================================

      - alert: UnusuallyHighRequestVolume
        expr: |
          rate(calls_total{service_name="fintelli-backend"}[5m]) > 100
        for: 2m
        labels:
          severity: warning
          service: fintelli-backend
          category: anomaly
          sla_impact: medium
        annotations:
          summary: "Volume de requisi√ß√µes unusualmente alto ({{ $value | humanize }} req/s)"
          description: |
            Volume de requisi√ß√µes ({{ $value | humanize }} req/s) est√° acima do normal.

            Poss√≠veis causas:
            - Pico de tr√°fego leg√≠timo
            - Poss√≠vel ataque DDoS
            - Bot ou scraping automatizado

            A√ß√µes recomendadas:
            - Verificar logs de acesso
            - Monitorar recursos do sistema
            - Considerar rate limiting

  # ========================================
  # RECORDING RULES PARA OTIMIZA√á√ÉO
  # ========================================
  - name: fintelli-spm-recording-rules
    rules:
      # M√©tricas agregadas para dashboards mais r√°pidos
      - record: fintelli:sla_availability_5m
        expr: |
          (
            1 - (
              rate(calls_total{service_name="fintelli-backend",status_code=~"5.."}[5m]) /
              rate(calls_total{service_name="fintelli-backend"}[5m])
            )
          ) * 100

      - record: fintelli:latency_p95_5m
        expr: |
          histogram_quantile(0.95,
            rate(duration_bucket{service_name="fintelli-backend"}[5m])
          )

      - record: fintelli:error_rate_5m
        expr: |
          (
            rate(calls_total{service_name="fintelli-backend",status_code=~"5.."}[5m]) /
            rate(calls_total{service_name="fintelli-backend"}[5m])
          ) * 100

      - record: fintelli:throughput_5m
        expr: |
          rate(calls_total{service_name="fintelli-backend"}[5m])
